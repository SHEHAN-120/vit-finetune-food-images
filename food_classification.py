# -*- coding: utf-8 -*-
"""Copy of Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f6lmOjnh1wGKxuaOJzjKbNnN_zAolp-S

## Install Libiraries
"""

!pip install datasets
!pip install -U accelerate
!pip install evaluate

import warnings
warnings.filterwarnings('ignore')

from datasets import load_dataset

food=load_dataset("rajistics/indian_food_images")

food['train'][0]['image']

labels=food['train'].features['label'].names
label2id,id2label=dict(),dict()

for i,label in enumerate(labels):
  label2id[label]=i
  id2label[i]=label

print(label2id)
print(id2label)

"""## Preprocessing and Evaluator"""

from transformers import AutoImageProcessor

model_ckpt="google/vit-base-patch16-224-in21k"
image_processor=AutoImageProcessor.from_pretrained(model_ckpt,use_fast=True)

from torchvision.transforms import RandomResizedCrop,Compose,Normalize,ToTensor

normalize=Normalize(mean=image_processor.image_mean,std=image_processor.image_std)

size=(
    image_processor.size['shorted_edge']
    if "shorted_edge" in image_processor.size
    else (image_processor.size['height'],image_processor.size['width'])
    )

_transforms=Compose([RandomResizedCrop(size),ToTensor(),normalize])

def transforms(examples):
  examples['pixel_values']=[_transforms(img.convert('RGB')) for img in examples['image']]
  del examples['image']

  return examples

food=food.with_transform(transforms)

"""## Evaluate the Model"""

import evaluate
import numpy as np

accuracy=evaluate.load('accuracy')

def compute_metrics(eval_pred):
  predictions,labels=eval_pred
  predictions=np.argmax(predictions,axis=1)

  return accuracy.compute(predictions=predictions,references=labels)

"""## Fine Tuning"""

from transformers import AutoModelForImageClassification,TrainingArguments,Trainer
import torch

device=torch.device("cuda" if torch.cuda.is_available() else "cpu")

model=AutoModelForImageClassification.from_pretrained(
    model_ckpt,
    num_labels=len(labels),
    id2label=id2label,
    label2id=label2id
).to(device)

args=TrainingArguments(
    output_dir="train_dir",
    remove_unused_columns=False,
    eval_strategy='epoch',
    save_strategy='epoch',
    learning_rate=5e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    gradient_accumulation_steps=4,
    num_train_epochs=4,
    warmup_ratio=0.1,
    load_best_model_at_end=True,
    metric_for_best_model='accuracy',
    report_to="none"

)

trainer=Trainer(
    model=model,
    args=args,
    train_dataset=food['train'],
    eval_dataset=food['test'],
    tokenizer=image_processor,
    compute_metrics=compute_metrics
)

!pip uninstall -y wandb

trainer.train()

"""## Save Model and Get Infernence"""

trainer.save_model('food_classification')

from transformers import pipeline

pipe=pipeline("image-classification",model="food_classification",device=device)

import requests
from PIL import Image
from io import BytesIO

url='https://marketplace.canva.com/fyIYY/MAGoWUfyIYY/1/tl/canva-overhead-shot-of-mushroom-pizza-MAGoWUfyIYY.jpg'
reponse=requests.get(url)
image=Image.open(BytesIO(reponse.content))
image.show()

pipe(image)

